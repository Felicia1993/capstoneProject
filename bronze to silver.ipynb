{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b6bc4ec-1297-414c-b5fc-d8d3c0539924",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  Using spark sql, query the parquet file to return the total athletes of each country, then store the data into silver folder\n",
    "configs = {\n",
    "  \"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "  \"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")\n",
    "}\n",
    "\n",
    "# Optionally, you can add <directory-name> to the source URI of your mount point.\n",
    "dbutils.fs.mount(\n",
    "  source = \"abfss://transformtest1@justforgen2.dfs.core.windows.net/\",\n",
    "  mount_point = \"/mnt/transformtest1\",\n",
    "  extra_configs = configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "516cfe13-513e-479b-8b77-33baec9075b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n|             Country|num|\n+--------------------+---+\n|United States of ...|615|\n|               Japan|586|\n|           Australia|470|\n|People's Republic...|401|\n|             Germany|400|\n|              France|377|\n|              Canada|368|\n|       Great Britain|366|\n|               Italy|356|\n|               Spain|324|\n|                 ROC|318|\n|              Brazil|291|\n|         Netherlands|274|\n|   Republic of Korea|223|\n|         New Zealand|202|\n|              Poland|195|\n|           Argentina|180|\n|        South Africa|171|\n|              Mexico|155|\n|             Hungary|155|\n+--------------------+---+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# create a temporary sql view for querying athletes information\n",
    "atheletes_data = spark.read.parquet('/mnt/transformtest1/bronze/athletes.parquet')\n",
    "atheletes_data.createOrReplaceTempView('AtheletesTable')\n",
    "\n",
    "# Print the total number of athletes  (the number of rows in the athletes data).\n",
    "# print(\"Number of athletes: \", atheletes_data.count())\n",
    "# atheletes_data.show(25, False)\n",
    "\n",
    "# # Using spark sql, query the parquet file to return the total athletes of each country\n",
    "num_athletes_by_country=spark.sql(\"SELECT Country, count(*) AS num FROM AtheletesTable GROUP BY Country ORDER BY num desc\")\n",
    "num_athletes_by_country.show()\n",
    "out_put=\"/mnt/silver/\"\n",
    "num_athletes_by_country.write.format(\"delta\").mode(\"overwrite\").save(out_put)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze to silver",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
